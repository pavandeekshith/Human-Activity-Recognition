{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code used to trim the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame for downstairs_3.csv after cleaning:\n",
      "          time     gFx     gFy     gFz\n",
      "1063  2.500068  0.0253  0.8080  0.3557\n",
      "1064  2.502304  0.0204  0.8127  0.3569\n",
      "1065  2.504117  0.0222  0.8239  0.3557\n",
      "1066  2.507878  0.0209  0.8359  0.3543\n",
      "1067  2.508850  0.0234  0.8491  0.3477\n",
      "\n",
      "DataFrame for downstairs_2.csv after cleaning:\n",
      "          time     gFx     gFy     gFz\n",
      "1061  2.502106 -0.0357  0.9580  0.2829\n",
      "1062  2.502932 -0.0345  0.9463  0.2761\n",
      "1063  2.506413 -0.0331  0.9341  0.2719\n",
      "1064  2.508178 -0.0294  0.9187  0.2658\n",
      "1065  2.509012 -0.0267  0.9070  0.2617\n",
      "\n",
      "DataFrame for downstairs_1.csv after cleaning:\n",
      "         time     gFx     gFy     gFz\n",
      "155  2.501000 -0.0453  0.9561  0.3286\n",
      "156  2.502369 -0.0702  0.9475  0.3332\n",
      "157  2.504960 -0.0746  0.9304  0.3039\n",
      "158  2.507663 -0.0670  0.9070  0.2673\n",
      "159  2.510206 -0.0650  0.8855  0.2619\n",
      "\n",
      "DataFrame for downstairs_4.csv after cleaning:\n",
      "          time     gFx     gFy     gFz\n",
      "1065  2.500856 -0.0511  0.7538  0.2277\n",
      "1066  2.503774 -0.0492  0.7675  0.2279\n",
      "1067  2.505786 -0.0460  0.7836  0.2296\n",
      "1068  2.508233 -0.0416  0.7970  0.2306\n",
      "1069  2.509615 -0.0382  0.8119  0.2316\n",
      "\n",
      "Concatenated DataFrame:\n",
      "       time     gFx     gFy     gFz\n",
      "0  2.500068  0.0253  0.8080  0.3557\n",
      "1  2.502304  0.0204  0.8127  0.3569\n",
      "2  2.504117  0.0222  0.8239  0.3557\n",
      "3  2.507878  0.0209  0.8359  0.3543\n",
      "4  2.508850  0.0234  0.8491  0.3477\n",
      "\n",
      "Data cleaning, processing, and concatenation completed for all files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1h/mqtvs8qd6kbfjkgs026sd7640000gn/T/ipykernel_58696/669067966.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the folder containing your CSV files\n",
    "folder_path = './Combined/Deployment/Walk'  # Replace with the actual folder path\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# Create an empty list to store individual cleaned DataFrames\n",
    "cleaned_dfs = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Construct the full path to the CSV file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Data Cleaning Operations:\n",
    "\n",
    "        # 1. Remove 'TgF' column\n",
    "        df = df.drop('TgF', axis=1)\n",
    "\n",
    "        # 2. Filter based on 'time' column\n",
    "        df = df[(df['time'] >= 2.5) & (df['time'] <= 12.5)]\n",
    "\n",
    "        # Append the cleaned DataFrame to the list\n",
    "        cleaned_dfs.append(df)\n",
    "\n",
    "        # Display the DataFrame with cleaned data\n",
    "        print(f\"\\nDataFrame for {file_name} after cleaning:\")\n",
    "        print(df.head())\n",
    "\n",
    "        # Save the modified DataFrame to a new CSV file\n",
    "        cleaned_file_path = os.path.join(folder_path, f'cleaned_{file_name}')\n",
    "        df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Concatenate all cleaned DataFrames based on the 'time' column\n",
    "final_df = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(\"\\nConcatenated DataFrame:\")\n",
    "print(final_df.head())\n",
    "\n",
    "# Save the concatenated DataFrame to a new CSV file\n",
    "concatenated_file_path = os.path.join(folder_path, 'Walking_Upstairs.csv')\n",
    "final_df.to_csv(concatenated_file_path, index=False)\n",
    "\n",
    "print(\"\\nData cleaning, processing, and concatenation completed for all files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
